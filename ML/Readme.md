# NLP machine learning

## Tf-Idf

<!-- todo create tf idf explanation here -->

## Word Embeddings

For the purpose of the project we are using 2 types of word embeddings. 
1. Word2Vec with gensim
2. FastText

### Gensim
<!-- todo explain more -->
In the `gensim_word_embeddings.py` file a Word2Vec model is created and trained with our dataset

### FastText
<!-- todo explain more -->
In the `fasttext_pretrained_embeddings.py` file. A pretrained fasttext model is imported and used.

Instructions for setting up the fasttext module are [here](https://fasttext.cc/docs/en/support.html#building-fasttext-python-module)
Instructions for downloading and using the model are [here](https://fasttext.cc/docs/en/crawl-vectors.html) 

## Transformers

## Bert
<!-- todo explain more -->
The `bert-base-multilingual-uncased` pre-trained model is used.